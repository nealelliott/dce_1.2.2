Revised Recovery and Salvage Tests Plan - 10/1/92
=================================================

Existing Tools
--------------

1 Recovery

 1.1 RCX (Recovery Exerciser).

  Does operations involving intensive metadata modifications
  and checks if the system is in a consistent state after
  running recovery. 

  Note: This has not been attempted on non-AIX [ 3.1/3.2 ] platforms .

 1.2 asdb.

  A program to freeze all operations on an aggregate. Currently used
  in conjunction with RCX.  

 1.3 Findlog 

  Extract the log from an aggregate. 

 1.4 Readlog

  Takes output of findlog and generates a human-readable log file.

 1.5 Testbuf

  Takes output of Readlog and generates a script that when run
  will replay the log. The script has its own language.

2 Salvager:

 2.1 Ravager

  Bashes disk blocks in an aggregate to all 0's, 1's, swaps meta-data
  disk blocks, copied a meta-data disk block into the next meta-data
  disk block and then runs salvager. Also includes a tool scp to do
  sparse copy.

 2.2 Scavenger

  Locates episode objects satisfying specified characteristics,
  modifies particular attributes of these objects and then runs salvager.

 2.3 Metamucil

  Tool to compact storing of an aggregate for salvage tests.
  Essentially zeroes out data blocks of the aggregate.


Testing Required
----------------

1 Common Tests: 

 1.1 Authorization Check Tests.

	PRI		1
 	ET		1
	AT 		2

  Only users with read access to the device file for the aggregate can
  issue salvage verification requests. If the user does not have read
  access to the device, the verification request should fail. Similarly
  for actual salvage and recovery, the user needs write access to the
  device file.
 
  1.1.1 Basic Tests.

   Run of the commands mentioned below in the scenario described
   beneath it. In each case, we expect success. 

   Command: 
    salvage -help

    - User is root.
    - User is not root.

   Command:
    salvage -readonly 

    - User is root. Aggregate owned by user. 
    - User is root. Aggregate not owned by user. 
    - User is not root. Aggregate readable by user. 

   Commands:
    salvage -verify    
    salvage -nosalvage 
    salvage -norecover 
    salvage            
  
    - User is root. Aggregate owned by user. 
    - User is root. Aggregate not owned by user. 
    - User is not root. User has write permission to the device.

  1.1.2 Error Tests.

   Run of the commands mentioned below in the scenario described
   beneath it. In each case, we expect FAILURE.

   Command: 
    salvage -readonly 

    - User is not root. Aggregate not readable by user. 
  
   Commands:
    salvage -verify    
    salvage -nosalvage 
    salvage -norecover 
    salvage            
  
    - User is not root.  Aggregate not writeable by user. 


 1.2 Mounted Filesets Error Tests.

	PRI		4
 	ET		3
	AT 		

  Test interaction of fileset mounts and salvage/recovery.

  1.2.1 Salvage/recovery on aggregates containing filesets that 
   have been mounted by users, should fail.

   Run each of the commands mentioned below on an aggregate containing
   filesets, that have been mounted by users. Number of filesets
   mounted from an aggregate should vary from one to all. The cases
   mentioned below need to tested on both standalone Episode and
   Episode under DFS. 

   For the following case, the command should succeed but should also
   issuing a warning.

     salvage -readonly     

   (Q: What is the format of the warning? )

   For each of the cases mentioned below, we expect FAILURE.

     salvage -verify    
     salvage -nosalvage 
     salvage -norecover 
     salvage 	       
   
  1.2.2 Mounting filesets from aggregates on which salvage/recovery is
   being run, should fail.

   Mount a fileset from the aggregate at the same time as one of the
   above command is being run. The cases mentioned below need to
   tested on both standalone Episode and Episode under DFS. The
   expected behavior of commands will be the same as mentioned in
   section 1.2.1.
  
   We need to ensure that the salvage on the aggregate is in progress,
   when fileset mounts are attempted. Two approaches are outlined
   below.

    - The salvager code can be instrumented to sleep after having done
      the necessary locking in its path and to send a signal to a
      process to a specified process and to wake up on receipt of a
      specific signal.  

    - The second approach would rely on the salvager printing a
      specific message after having done the necessary locking. A
      monitor process would detect this message and send the salvager
      process a SIGSTOP signal. Then the monitor process can attempt
      the fileset mounts. On completion of the fileset mounts, it
      would issue a SIGCONT signal to the salvager. For detection of
      the message, an expect script would be ideal. Additionally, the
      priority of the salvager process could be reduced using the
      "nice" command to provide a little more guarantee that the
      salvager would be running when the mounts are attempted.  The
      second approach seems to be preferable as it involves less
      interference with the salvager code.

   NOTE: Currently the code to implement features mentioned in 1.2.1
   and 1.2.2 has not been implemented in Episode and DFS. It is
   expected to be done in the future but time for it has not been
   allocated to the development group yet.

 1.3 Log on a different aggregate.  

	PRI		NA (Defer)
 	ET		NA
	AT 		NA

  The design specifications mention that the log for an aggregate can
  be created on another aggregate.  

  NOTE: Currently the log for an aggregate cannot reside on another
  aggregate. There is no definite schedule for the implementation of
  this feature. Hence implementation of this test should be deferred.

 1.4 Robustness Tests.  

	PRI		5 (Defer)
 	ET		1
	AT 		

  1.4.1 Verbose Option Tests 
  
   Issue commands that should succeed but with an additional verbose
   option.

  1.4.2 Error Tests 
 
   For each of the following commands pass less/extra/incorrect
   arguments and check for FAILURE.  

   Commands: 
    salvage -readonly
    salvage -verify 
    salvage -nosalvage 
    salvage -norecover 
    salvage
    salvage -help 

   Repeat each of the cases mentioned with an additional -verbose flag. 

2 Recovery: 

 2.1 Stress Tests.

  Operations involving metadata updates are carried out on the
  aggregate. The aggregate is frozen at various points and after
  recovery is done, the filesystem is checked for consistency. 

  Types of operations are:

  2.1.1 RCX tests 

   RCX tests perform intensive updates of specific types of metadata. 
   These tests exist and are implemented as perl scripts. However they
   need enhancements as outline below

    2.1.1.1 Modify RCX to use efts

	 PRI 	1
	 ET		2
	 AT		
 
     Currently, the RCX uses newvol to create filesets. Since newvol is
	 now obsolete and has been replaced by efts, the tests should be
	 changed to use efts.

	2.1.1.2 Enhance RCX to use filesets with varying transaction
			concurrency.
	
	 PRI	1
	 ET		2
	 AT		
    
     Currently, RCX creates fileset with minimum log size, which
	 restricts max. concurrent transactions to 1. Enhance RCX to vary the
	 log size in a controlled manner by creating fileset with appropriate
	 sized log. This essentially means duplication of some code in the
	 logbuf layer that performs "logsize -> transaction concurrency"
	 mapping.

	2.1.1.3 Extension of systems calls exercised.

	 PRI	1
	 ET		4
     AT		

 	 Currently, RCX tests only open(O_CREAT), unlink, mkdir, rmdir,
	 rename, chmod. Enhancement would include adding support for
     chown, chgrp, truncate, open(O_APPEND), read, write, symlink,
     link, mkfifo, mknod and utimes. The scripts with .rs suffix also
     need to be written to use these additional system calls.
   
	2.1.1.4 Enhance process staggering mechanism.
	
	 PRI	2
	 ET		2
     AT		

	 RCX runs multiple process per fileset and attempts to stagger
	 them. Currently, staggering is achieved by stopping n-1 processes  and
	 letting the nth process run for "t"  time units (t is a random
	 number). At the end of "t" time units, the sleeping n-1 processes are
	 woken up. A better staggering mechanism would be useful.
	
   	2.1.1.5	
   



  2.1.2 Metadata updates using the fs and low tests. 

 	PRI	NA (Cancelled)
	ET	2
    AT		

    These tests have been cancelled as better stress generators are
    available such as AIM III tests.
	
   The scripts should be be able to run the tests sequentially and in
   parallel in different stress modes.

   Interface: fslowtest -level { normal | moderate } 
                        -suites { [ fs ] [ low ] }
                        -mode { sequential | parallel }

    level: normal - Runs each test with default arguments. 
           moderate - Runs each test with moderate stress mode arguments. 
    suites: fs - Runs fs test suite. 
            low - Runs low test suite. 
    mode: sequential - Runs each of the test in the suite one after the other
          parallel - Runs tests in a test suite in parallel

    DEFAULT: fslowtest -level normal -suite fs -mode sequential 

   Description: After each of the tests are run, all mounted filesets
   could be unmounted ensuring the metadata transactions are in the
   disk log rendering. Then recovery is done on the aggregate followed
   by salvage verification ( salvage -readonly) is done.

  2.1.3 Metadata updates by simultaneous running of the POSIX

	PRI	
	ET
	AT

   Conformance Test Suite (PCTS), compilation within the aggregate in
   question and "du" in the background.

   Currently these tests are run only on power7. Work needs to be done
   to package these tests to be self-contained. 

  2.1.4 Tool to freeze aggregate and verify it. 

   Work needs to be done to implement a mechanism to run "asdb" to
   freeze the aggregate at intervals, copy the aggregate, run
   recovery/salvage as appropriate, to save the output, verify it and
   unfreeze the aggregate. This mechanism should be general. Studying
   existing RCX scripts can be useful here.

  2.1.5 Packaging. 

   Work needs to be done to package these stress tests and also to
   verify that they are self-checking.

 2.2 Synchronous modifications. 
 
  2.2.1 Write system call.  

   In Episode, when a file is opened in synchronous mode (with
   O_SYNC), the write() system call will return only after the file
   userdata is flushed to disk and the metadata update log record for
   the file status had been written to the disk log. For UFS, the
   userdata and the metadata would be written out to disk. Freeze the
   system after such operations. Copy the aggregate and run recovery
   and check if the relevant metadata updates occurred. (using
   scavenger). 

   NOTE: This case can be subsumed by a write() followed by a fsync()
   as mentioned below. Hence this is not to be implemented.

  2.2.2 File metadata updates with fsync().

   The fsync() system call causes any pending user-data to be flushed
   to disk and also for any meta-data transactions in the incore log
   to be flushed to disk. There is no guarantee provided about the
   flushing of the metadata itself to disk. But after recovery, the
   metadata should be updated on the disk.  

   Run various metadata update system calls followed by fsync. Freeze
   aggregate.  Copy the aggregate to another file, run recovery and
   check if the relevant metadata updates occurred.  Various candidate
   system calls: creat/open, read, write, [f]chgrp, [f]chmod,
   [f]chown, ftruncate, utime and link.

  2.2.3 File/Dir metadata updates with the "Fileset fsync" call.  
 
   There is a system call that will "fsync" all pending buffers for
   the specified fileset. This system call will guarantee fsync
   semantics for system calls like mkdir, rmdir, rename, mkfifo,
   mknod, symlink for which fsync semantics cannot be ensured using
   the fsync() call. Follow the test algorithm mentioned in 2.2.2.
 
   The relevant system call is afs_syscall(VOLOP_FSYNC, VDESC) where
   VOLOP_FSYNC specifies the "fileset fsync" operation and VDESC is
   the fileset descriptor.  

  2.2.4 Fileset/Aggregate level metadata updates.

   Using the ftu_FsetSetStatus call, fileset level metadata can be
   explicitly modified. Similarly, the ftu_AggrFsetSetStatus call,
   aggregate level metadata can be explicitly modified. These calls in
   combination with the "fileset sync" calls can be used to test
   recovery.

 2.3 New Block Security (NBS) Tests.
  
  To verify NBS, the possible approaches are

    2.3.1 Write with RCX

     Fill a disk with a pattern P1. Issue writes into a file with
     another pattern P2 using RCX. At various points in this process
     freeze the aggregate, run recovery and check for consistency of
     file data. RCX may need to be modified for this. This approach could
     be given up in favor of the following approach.

    2.3.2 Sync/Async write with I/O stepping.

     This would involve issuing writes both in synchronous and
     asynchronous modes. For each of the modes, 2 approaches are
     possible. First, the aggregate could be frozen after the write
     returns. Secondly the aggregate can be frozen just before the
     write is made, followed by disk activity on a single step basis
     (using asdb) with NBS checks at each step. This may also involve
     usage of sync() to ensure that the userdata is flushed to disk
     within a convenient time interval specially in VM integrated
     systems. Additionally, in VM integrated systems, to enforce
     flushing of the memory pool pages, another process can be used
     that continuously malloc's memory in a loop.
  
     To prevent the writing of a tool to fill the disk with a
     particular pattern, the data that is written should be unique,
     possibly a clock-based random sequence.

 NOTE: Ted expects completion of NBS implementation by end of August. 
 Hence the tests should be scheduled appropriately.

 2.4 Special Regression Tests.

  Aggregates on which recovery succeeds but salvage verification fails
  are of interest here. The corresponding logs and the salvage output
  should be stored. Recovery using these logs should be repeated and the 
  output of salvage verification compared with outputs from previous runs. 
  Use compaction schemes to the extent possible, to store the logs and
  their resulting outputs. Usage of findlog, readlog and testbuf can be
  used here.
  
  Note: This may be better done by the development group. Tony has
  partially implemented this and probably will be looking into this in
  the future.

 2.5 Branch Coverage Analysis.

  Augmentation of tests with branch coverage analysis using btool.

3 Salvager:

 3.1 Stress tests.

  Run filesystem metadata intensive stress tests, freeze the aggregate
  at various points and perform salvage on it. These tests will be tied in 
  with the corresponding stress tests for recovery.

 3.2 Generation of aggregates with interesting characteristics. 

  The following features are some of the interesting characteristics.
    Clones - Large filesets, many small filesets.
    ACL's -  shared, large.
    Full filesets.
    Deleted open files and directories 
  These aggregates will be used with ravager & scavenger tools.

 3.3 Special Regression tests.

  Store bad aggregates. Run salvage on these aggregates and
  compare output with the output from previous runs of salvage. 

  Aggregates on which salvage fails and/or core dumps are of interest
  here. The corresponding aggregates and the salvage output should be
  stored. Salvage using these aggregates should be repeated and the
  output of salvage compared with outputs from previous runs.  Use
  compaction schemes to the extent possible, to store the aggregates and
  the outputs of salvage. 

  The basic mechanism exists here and packaging needs to be done.

 3.4 Branch Coverage Analysis.

  Augmentation of tests with branch coverage analysis using btool.

Time Estimates
--------------

Note: The following time estimates do not, in general, include time to
build tools that make the running and rerunning of these tests easy. 

1 Common Tests:

 1.1 Authorization check.

  ET: 1 day

 1.2 Aggregates with mounted filesets.

  ET: 2.0 days

 1.3 Log on a different aggregate.

  ET: Not Available

 1.4 Robustness Tests
  Check if the salvage command validates input arguments or not.
  ET: 1 day

2 Recovery:

 2.1 Stress Tests:

  2.1.1 Intensive updates of specific types of metadata.
   Tests exist but need to acquire familiarity with them.
   ET: 1 day

  2.1.2 General metadata updates by running the fs and low tests.
   ET: 2 days

  2.1.3 Tests using the PCTS, compilation and "du".
   ET: 2 days.

  2.1.4 Packaging
   ET: 3 days 

  2.1.5 Tool to freeze aggregate and verify it.
   ET: 5 days

 2.2 Synchronous file creation and modifications.

  2.2.1 Write system call
   ET: 1 day
  
  2.2.2 File metadata updates with fsync().
   ET: 2 days
  
  2.2.3 File/Directory metadata updates with the "Fileset fsync" call.  
   ET: 2 days

  2.2.4 Fileset/Aggregate level metadata updates.
   ET: 2 days
   
 2.3 NBS tests.
 
  2.3.1 Writes with RCX
   ET: Not Applicable

  2.3.2 Async/Async write with I/O stepping.
   ET: 5 days 
  
 2.4 Special Regression Tests
  ET: 10 days

 2.5 Branch Coverage Analysis
  This would be better done by the development group than the testing group.
  ET: 3+ days

3 Salvager:

 3.1 Stress tests.
  The can be tied in with the corresponding stress tests in recovery.
  ET: 1 day

 3.2 Creation of aggregates with interesting characteristics
   ET: 3 days

 3.3 Special Regression tests.

  ET: 2 days

 3.4 Branch Coverage Analysis
  This would be better done by the development group than the testing
  group.
  ET: 3+ 

Overall Summary of Time Estimates 
---------------------------------

(Time unit - day)

Common Tests 			
  Authorization Checks	         1  
  Mounted filesets		 2   
  Log on different aggregate   NA
  Robustness		         1       	 
						 4 
Recovery Tests 				
  Stress 		 	13   
  Sync  		 	 7  
  NBS    		 	 5  
  Special Regression 		10  
  Branch Coverage	 	 3+ 
						38+ 
Salvager Tests 				
  Stress      			 1  
  Aggregate Generation  	 3  
  Special Regression   		 2  
  Branch Coverage		 3+ 
						 9+ 

Acquire familiarity with Perl 			 3   
 	
						---
   				TOTAL TIME      54+ 
						---

Task Allocation and Priority
----------------------------

The above tasks are to be split up between the development group and
the testing groups as mentioned below.

Development Group:

  Recovery Tests - Regression, Branch Coverage
  Salvager Tests - Branch Coverage.

  TIME: 16 days

Testing Group: 
(Items are listed in order of suggested priority)

  Common Tests
    Authorization Checks	
    Robustness		    
  Recovery Tests
    Stress
    Sync
  Salvager Tests
    Stress
    Aggregate Generation
    Regression 
  Common Tests
    Mounted Filesets 
  Recovery
    NBS

  Acquiring familiarity with Perl will be a continuous process with time
  allocated as necessary.

  TIME: 38 days

NOTE: If generally acceptable, the responsibility for the Recovery
Regression Tests could be taken by the testing group.

Time Estimates for running the tests
------------------------------------

  Common Tests			
    Authorization Checks	      	1
    Robustness		            	1

  Recovery Tests		 
    Stress 				6
    Sync			    	4

  Salvager Tests		 
    Stress			    	6
    Aggregate Generation	    	3
    Regression 			    	1 *

  Common Tests			 
    Mounted filesets		    	2

  Recovery			 
    NBS				    	5

	                                --				       
	                    TOTAL TIME: 29
                                        --		

  * Time for the initial sample runs only. 

Notes added 2/94 by Bruce Leverett
==================================

The RCX tests have been modified to use efts.

An important component of the salvager tests is the "ravager".
At this time the ravager has four subcases:  bash disk blocks to all 0's and
salvage; bash disk blocks to all 1's and salvage; swap disk blocks with each
other and salvage; copy disk blocks to other disk blocks and salvage.

A substantial component of the salvager tests is the "salt" test.  This
bashes an aggregate in a systematic way using knowledge of the disk structure,
e.g. change a magic number, or add one to a block count, or zero a block
pointer.  After each bashing it tests the salvager.

Another substantial component of the salvager tests is a collection of
aggregates obtained from past bug reports.  Scripts exist to salvage each of
these and to compare the results with saved logs of earlier salvages of the
same aggregates.  This corresponds to the "Special Regression Tests" described
above.
